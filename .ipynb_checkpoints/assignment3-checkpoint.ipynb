{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 : Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Please edit the cell below to include your name and student ID #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**name:** Kenny Tran\n",
    "\n",
    "**SID:** 87199643"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In this assignment we will build on top of your **project** and **triangulate** functions from previous assignments.  If you weren't happy with your implementation from assignment 2, please consult with the TAs or your classmates to get things cleaned up before starting this assignment.\n",
    "\n",
    "\n",
    "# 1. Parameterizing 3D Rotations\n",
    "\n",
    "In order to optimize over the camera rotation during calibration, we need a way to parameterize the space of 3D rotations. There are many different ways to do this and each comes with different tradeoffs, but for our purposes we will adopt a simple approach of building a rotation by a sequence of rotations around the X, Y and Z axes (so called *Tait-Bryan angles*, see https://en.wikipedia.org/wiki/Euler_angles for more discussion)\n",
    "\n",
    "## 1.1 Implement\n",
    "\n",
    "Write a function **makerotation** which takes as input three angles **rx,ry,rz** and returns a rotation matrix corresponding to rotating by **rx** degrees around the x-axis, followed by a rotation of **ry** degrees around the y-axis, followed by a rotation of **rz** degrees around the z-axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import visutils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makerotation(rx,ry,rz):\n",
    "    \"\"\"\n",
    "    Generate a rotation matrix    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rx,ry,rz : floats\n",
    "        Amount to rotate around x, y and z axes in degrees\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    R : 2D numpy.array (dtype=float)\n",
    "        Rotation matrix of shape (3,3)\n",
    "    \"\"\"\n",
    "    rx = rx * np.pi / 180\n",
    "    ry = ry * np.pi / 180\n",
    "    rz = rz * np.pi / 180\n",
    "    \n",
    "    X = np.array([[1,0,0],\n",
    "                 [0, np.cos(rx), -np.sin(rx)],\n",
    "                 [0, np.sin(rx), np.cos(rx)]])\n",
    "    \n",
    "    Y = np.array([[np.cos(ry),0,np.sin(ry)],\n",
    "                 [0,1,0],\n",
    "                 [-np.sin(ry),0,np.cos(ry)]])\n",
    "    \n",
    "    Z = np.array([[np.cos(rz), -np.sin(rz), 0],\n",
    "                 [np.sin(rz), np.cos(rz), 0],\n",
    "                 [0,0,1]])\n",
    "  \n",
    "    return Z@Y@X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Testing\n",
    "\n",
    "Work out by hand what a 90 degree rotation should look like around each axis.  Then execute the test examples below and add some tests (asserts) to make sure your code passes. \n",
    "\n",
    "Find a way to achieve the same rotation as **makerotation(90,90,0)** but without using rotation around the x-axis.  That is, determine some angles so that **makerotation(0,?,?) == makerotation(90,90,0)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  1.  0.]]\n",
      "[[ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [-1.  0.  0.]]\n",
      "[[ 0. -1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [-1.  0.  0.]]\n",
      "[[ 0.  1.  0.]\n",
      " [-0.  0. -1.]\n",
      " [-1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# test your function on some simple examples\n",
    "#\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "\n",
    "print(makerotation(90,0,0))\n",
    "\n",
    "print(makerotation(0,90,0))\n",
    "\n",
    "print(makerotation(0,0,90))\n",
    "\n",
    "print(makerotation(90,90,0))\n",
    "\n",
    "ry = 90\n",
    "rz = -90\n",
    "print(makerotation(0,ry,rz))\n",
    "\n",
    "# figure out what ry,rz values are needed in order to pass this test\n",
    "assert((makerotation(90,90,0)-makerotation(0,ry,rz)<1e-9).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reprojection Error\n",
    "\n",
    "We will now specify a function which computes the reprojection error.  This is the function that we will later optimize when calibrating the camera extrinsic parameters. Take a look at the documentation for **scipy.optimize.leastsq**.  The optimizer expects that our function should take a vector of parameters and \n",
    "return a vector of residuals which it will square and sum up to get the total error. For this reason, we will structure our code in the following way. \n",
    "\n",
    "First, write a member function for the Camera class called **update_extrinsics** which takes a vector of 6 parameters (rx,ry,rz,tx,ty,tz). The function should keep the same intrinsic parameters (f,c) but update the extrinsic parameters (R,t) based on the entries in the parameter vector.  \n",
    "\n",
    "Second, implement a function named **residuals** which computes the difference between a provided set of 2D point coordinates and the projection of 3D point coordinates by specified camera.  The residuals function takes as input the 3D points, the target 2D points, a camera with specified intrinsic parameters, and an extrinsic parameter vector. You should use **update_extrinsics** to update the extrinsic parameters, compute the projection of the 3D points with the updated camera and return a 1D vector containing the differences of all the x and y coordinates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camera:\n",
    "    \"\"\"\n",
    "    A simple data structure describing camera parameters \n",
    "    \n",
    "    The parameters describing the camera\n",
    "    cam.f : float   --- camera focal length (in units of pixels)\n",
    "    cam.c : 2x1 vector  --- offset of principle point\n",
    "    cam.R : 3x3 matrix --- camera rotation\n",
    "    cam.t : 3x1 vector --- camera translation \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,f,c,R,t):\n",
    "        self.f = f\n",
    "        self.c = c\n",
    "        self.R = R\n",
    "        self.t = t\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Camera : \\n f={self.f} \\n c={self.c.T} \\n R={self.R} \\n t = {self.t.T}'\n",
    "    \n",
    "    #     def project(self,pts3):\n",
    "    #         \"\"\"\n",
    "    #         Project the given 3D points in world coordinates into the specified camera    \n",
    "\n",
    "    #         Parameters\n",
    "    #         ----------\n",
    "    #         pts3 : 2D numpy.array (dtype=float)\n",
    "    #             Coordinates of N points stored in a array of shape (3,N)\n",
    "\n",
    "    #         Returns\n",
    "    #         -------\n",
    "    #         pts2 : 2D numpy.array (dtype=float)\n",
    "    #             Image coordinates of N points stored in an array of shape (2,N)\n",
    "\n",
    "    #         \"\"\"\n",
    "    \n",
    "    def getMext(self):\n",
    "        #Gets Extrinsic matrix: Matrix that converts World coordinates to Camera coordinates\n",
    "        # Receives a 3x1 vector \n",
    "        #  |R T|\n",
    "        #  |0 1|\n",
    "        y=np.concatenate((self.R.T,-self.R.T@self.t),axis=1)\n",
    "        #M_ex = np.concatenate((y, np.array([[0,0,0,1]])),axis=0)\n",
    "        return y#M_ex\n",
    "        \n",
    "    \n",
    "    def getMint(self):\n",
    "        \n",
    "        return np.array([[self.f,0,self.c[0][0]],\n",
    "                  [0,self.f,self.c[1][0]],\n",
    "                  [0,0,1]])\n",
    "        \n",
    "        \n",
    "    def getM_proj(self):\n",
    "        i = self.getMint()\n",
    "        e = self.getMext()\n",
    "#         print(\"Mint:\\n\",i)\n",
    "#         print(\"Mext:\\n\",e)\n",
    "        \n",
    "        p = i.dot(e)\n",
    "#         print(\"Proj:\\n\",p)\n",
    "        return p\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def project(self,pts3):\n",
    "        \"\"\"\n",
    "        Project the given 3D points in world coordinates into the specified camera    \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pts3 : 2D numpy.array (dtype=float)\n",
    "            Coordinates of N points stored in a array of shape (3,N)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pts2 : 2D numpy.array (dtype=float)\n",
    "            Image coordinates of N points stored in an array of shape (2,N)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        assert(pts3.shape[0]==3)\n",
    "\n",
    "        #Test\n",
    "        #         print(self.f)\n",
    "        #         print(self.c.shape)\n",
    "        #         print(self.R.shape)\n",
    "        #         print(self.t.shape)\n",
    "        # your code goes here\n",
    "        \n",
    "        def world_to_camera(point):\n",
    "            w = np.array([[point[0]],[point[1]],[point[2]],[1]])\n",
    "            p_matrix = self.getM_proj()\n",
    "#             print('----')\n",
    "#             print(p_matrix.dot(w).shape)\n",
    "#             print(p_matrix.dot(w))\n",
    "#             print('---')\n",
    "            ans = p_matrix.dot(w)\n",
    "            ans = ans / ans[2][0]\n",
    "            return (ans[0][0],ans[1][0])\n",
    "            \n",
    "            #return p_matrix.dot(w)\n",
    "        \n",
    "        pts2 = np.apply_along_axis(world_to_camera,0,pts3)\n",
    "        \n",
    "        #print(pts2)\n",
    "#         print(pts2.shape)\n",
    "#         print(pts3.shape)\n",
    "        \n",
    "        \n",
    "        assert(pts2.shape[1]==pts3.shape[1])\n",
    "        assert(pts2.shape[0]==2)\n",
    "    \n",
    "        return pts2\n",
    "\n",
    " \n",
    "    def update_extrinsics(self,params):\n",
    "        \"\"\"\n",
    "        Given a vector of extrinsic parameters, update the camera\n",
    "        to use the provided parameters.\n",
    "  \n",
    "        Parameters\n",
    "        ----------\n",
    "        params : 1D numpy.array of shape (6,) (dtype=float)\n",
    "            Camera parameters we are optimizing over stored in a vector\n",
    "            params[:3] are the rotation angles, params[3:] are the translation\n",
    "\n",
    "        \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(pts3,pts2,cam,params):\n",
    "    \"\"\"\n",
    "    Compute the difference between the projection of 3D points by the camera\n",
    "    with the given parameters and the observed 2D locations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pts3 : 2D numpy.array (dtype=float)\n",
    "        Coordinates of N points stored in a array of shape (3,N)\n",
    "\n",
    "    pts2 : 2D numpy.array (dtype=float)\n",
    "        Coordinates of N points stored in a array of shape (2,N)\n",
    "\n",
    "    params : 1D numpy.array (dtype=float)\n",
    "        Camera parameters we are optimizing stored in a vector of shape (6,)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    residual : 1D numpy.array (dtype=float)\n",
    "        Vector of residual 2D projection errors of size 2*N\n",
    "        \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Test the residual function to make sure it is doing the right thing.\n",
    "#\n",
    "\n",
    "# create two cameras with same intrinsic but slightly different extrinsic parameters\n",
    "camA = Camera(f=200,c=np.array([[50,50]]).T,t=np.array([[0,0,0]]).T, R=makerotation(0,0,0))\n",
    "camB = Camera(f=200,c=np.array([[50,50]]).T,t=np.array([[0,0,0]]).T, R=makerotation(0,0,0))\n",
    "\n",
    "paramsA = np.array([0,0,0,0.5,0.5,-2.5])\n",
    "paramsB = np.array([0,0,5,0.5,0.5,-3])\n",
    "camA.update_extrinsics(paramsA)\n",
    "camB.update_extrinsics(paramsB)\n",
    "\n",
    "print(camA)\n",
    "print(camB)\n",
    "\n",
    "# create a test object (corners of a 3D cube) \n",
    "pts3 = np.array([[0,0,0],[0,0,1],[0,1,1],[0,1,0],[1,1,0],[1,0,0],[1,0,1],[1,1,1]]).T\n",
    "\n",
    "# visualize the two projections\n",
    "pts2A = camA.project(pts3)\n",
    "pts2B = camB.project(pts3)\n",
    "\n",
    "plt.plot(pts2A[0,:],pts2A[1,:],'r')\n",
    "plt.plot(pts2B[0,:],pts2B[1,:],'b')\n",
    "plt.show()\n",
    "\n",
    "# double check that the residuals are the same as the difference in the reprojected coordinates\n",
    "print(\"\\n residuals of camB relative to camA\")\n",
    "print(residuals(pts3,pts2A,camB,paramsB))\n",
    "print(pts2A-pts2B)\n",
    "\n",
    "print(\"\\n residuals of camA relative to camB\")\n",
    "print(residuals(pts3,pts2B,camA,paramsA))\n",
    "print(pts2B-pts2A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Camera Pose Estimation\n",
    "\n",
    "We are now ready to estimate camera pose using optimize.  Implement a function **calibratePose** which takes as input the 3D coordinates of a calibration object, the observed 2D coordinates in the image, and an initial guess of the camera. Your function should use **scipy.optimize.leastsq** to optimize the extrinsic parameters in order to minimize the reprojection error. Since the **residuals** function takes additional arguments and **leastsq** expects a function which only takes the parameter vector as input, you should use Python's **lambda** function to wrap **residuals**, subistituting in the parameters that are fixed during the optimization. Once you have determined the optimum parameters, update the extrinsic parameters to the optimum and return the resulting camera.\n",
    "\n",
    "\n",
    "## 3.1 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibratePose(pts3,pts2,cam,params_init):\n",
    "    \"\"\"\n",
    "    Calibrate the provided camera by updating R,t so that pts3 projects\n",
    "    as close as possible to pts2\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pts3 : 2D numpy.array (dtype=float)\n",
    "        Coordinates of N points stored in a array of shape (3,N)\n",
    "\n",
    "    pts2 : 2D numpy.array (dtype=float)\n",
    "        Coordinates of N points stored in a array of shape (2,N)\n",
    "\n",
    "    cam : Camera\n",
    "        Initial estimate of camera\n",
    "        \n",
    "    params_init : 1D numpy.array (dtype=float)\n",
    "        Initial estimate of camera extrinsic parameters ()\n",
    "        params[0:2] are the rotation angles, params[2:5] are the translation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cam : Camera\n",
    "        Refined estimate of camera with updated R,t parameters\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Synthetic Test Example and Failure Cases\n",
    "\n",
    "Use the code below to check that your calibrate function works. Add some code to also visualize the point locations in 3D and the location and orientation of the camera (i.e., using the 3D plotting functions from Assignment 2)\n",
    "\n",
    "Once you are confident that your calibration function is behaving correctly, you should experiment with changing the initial parameters.  Find a set of initial parameters which yields a ***wrong*** solution (i.e. where the Final Camera is not similar to the True Camera).  In the text box below indicate what bad initialization you used and the resulting set of camera parameters after the optimization. Give a brief explanation of where this bad camera is located and what direction it is oriented in.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D calibration object\n",
    "pts3 = np.array([[0,0,0],[0,0,1],[0,1,1],[0,1,0],[1,1,0],[1,0,0],[1,0,1],[1,1,1]]).T\n",
    "\n",
    "# true camera\n",
    "cam_true = Camera(f=50,c=np.array([[50,50]]).T,t=np.array([[-1,-1,-2]]).T, R=makerotation(10,0,0))\n",
    "\n",
    "print(\"\\n True Camera\")\n",
    "print(cam_true)\n",
    "\n",
    "# image of calibration object with some simulated noise in the 2D locations\n",
    "pts2 = cam_true.project(pts3)\n",
    "noiselevel = 0.5\n",
    "pts2 = pts2 + noiselevel*np.random.randn(pts2.shape[0],pts2.shape[1])\n",
    "\n",
    "# initial guess of camera params\n",
    "cam = Camera(f=50,c=np.array([[50,50]]).T,t=np.array([[0,0,0]]).T, R=makerotation(0,0,0))\n",
    "params_init = np.array([0,0,0,0,0,-2]) \n",
    "cam.update_extrinsics(params_init)\n",
    "\n",
    "print(\"\\n Initial Camera\")\n",
    "print(cam)\n",
    "pts2init = cam.project(pts3)\n",
    "\n",
    "# now run calibration\n",
    "cam = calibratePose(pts3,pts2,cam,params_init)\n",
    "\n",
    "print(\"\\n Final Camera\")\n",
    "print(cam)\n",
    "pts2final = cam.project(pts3)\n",
    "\n",
    "#\n",
    "# Plot the true, initial and final reprojections\n",
    "# The final reprojection should be on top of the true image\n",
    "#\n",
    "plt.plot(pts2[0,:],pts2[1,:],'bo')\n",
    "plt.plot(pts2init[0,:],pts2init[1,:],'r')\n",
    "plt.plot(pts2final[0,:],pts2final[1,:],'k')\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "# Add some additional visualiztion here to show the points in 3D and the locations and orientations\n",
    "# of cam_true and cam.  You can either use a 3D plot or show multiple 2D plots (e.g. overhead\n",
    "# and side views)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now repeat the calibration but with a setting for params_init that results\n",
    "# in the optimization finding a poor solution (a bad local minima)\n",
    "#\n",
    "\n",
    "#\n",
    "# Visualize the resulting bad solution.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[**describe the failure mode here... how is the camera located and oriented for the bad local minima?**]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calibration from real images\n",
    "\n",
    "There is a provided set of calibration images (images of a planar checkerboard) along with stereo pair depicting an object. In order to calibrate the intrinsic camera parameters we will use the OpenCV library which includes functionality for automatically detecting corners of the checkerboard and estimating intrinsic parameters. To install OpenCV python libraries in your Anaconda environment. You can do this from the terminal via the command **conda install opencv** or via the Anconda Navigator gui.\n",
    "\n",
    "I have provide a standalone script **calibrate.py** which uses OpenCV to carry out calibration of the camera intrinsic parameters for a series of checkerboard images. Read through the provided script to understand the code and modify file paths as necessary in order to compute the intrinsic camera parameters from the set of provided calibration images.\n",
    "\n",
    "\n",
    "## 4.1 Implementation\n",
    "\n",
    "Fill in the code snippet below to carry out the following steps.\n",
    "\n",
    "0. Run the **calibrate.py** script to estimate the intrinsic camera parameters.\n",
    "\n",
    "1. Load in the intrinsic parameter calibration data saved by the script in *calibration.pickle*. Since our camera model assumes that the focal length is the same in the x and y axes, you can set your f to be the average of the two estimated by the script.\n",
    "\n",
    "2. Load in the test images *Left.jpg* and *Right.jpg* and use the **cv2.findChessboardCorners** function in order to automatically get the 2D coordinates of the corners in the image.\n",
    "\n",
    "3. Specify the true 3D coordinates of the 6x8 grid of checkerboard corners. The squares are 2.8cm x 2.8cm.\n",
    "\n",
    "5. Use your **calibratePose** function to estimate the R,t for each camera. You will likely need to experiment with selecting the initial parameters in order to get a good solution (e.g., translate so the cameras have positive z coordinates and rotate so they are looking down on the checkerboard).\n",
    "\n",
    "6. Finally, as a consistency check, once you have the calibrated pose for each camera, you can use your triangulate function to estimate the 3D coordinates of the checkerboard corners based on the 2D points in the left and right camera. The re-triangulated points should be close to the specified true 3D coordinates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# load in the intrinsic camera parameters from 'calibration.pickle'\n",
    "...\n",
    "\n",
    "# create Camera objects representing the left and right cameras\n",
    "# use the known intrinsic parameters you loaded in.\n",
    "camL = Camera(...)\n",
    "camR = Camera(...)\n",
    "\n",
    "# load in the left and right images and find the coordinates of\n",
    "# the chessboard corners using OpenCV\n",
    "imgL = plt.imread('calib1/Left.jpg')\n",
    "ret, cornersL = cv2.findChessboardCorners(imgL, (8,6), None)\n",
    "pts2L = cornersL.squeeze().T\n",
    "\n",
    "imgR = plt.imread('calib1/Right.jpg')\n",
    "ret, cornersR = cv2.findChessboardCorners(imgR, (8,6), None)\n",
    "pts2R = cornersR.squeeze().T\n",
    "\n",
    "# generate the known 3D point coordinates of points on the checkerboard in cm\n",
    "pts3 = np.zeros((3,6*8))\n",
    "yy,xx = np.meshgrid(np.arange(8),np.arange(6))\n",
    "pts3[0,:] = 2.8*xx.reshape(1,-1)\n",
    "pts3[1,:] = 2.8*yy.reshape(1,-1)\n",
    "\n",
    "\n",
    "# Now use your calibratePose function to get the extrinsic parameters\n",
    "# for the two images. You may need to experiment with the initialization\n",
    "# in order to get a good result\n",
    "\n",
    "...\n",
    "\n",
    "camL = calibratePose(...)\n",
    "camR = calibratePose(...)\n",
    "\n",
    "print(camL)\n",
    "print(camR)\n",
    "\n",
    "# As a final test, triangulate the corners of the checkerboard to get back there 3D locations\n",
    "pts3r = triangulate(...)\n",
    "\n",
    "# Display the reprojected points overlayed on the images to make \n",
    "# sure they line up\n",
    "plt.rcParams['figure.figsize']=[15,15]\n",
    "pts2Lp = camL.project(pts3)\n",
    "plt.imshow(imgL)\n",
    "plt.plot(pts2Lp[0,:],pts2Lp[1,:],'bo')\n",
    "plt.plot(pts2L[0,:],pts2L[1,:],'rx')\n",
    "plt.show()\n",
    "\n",
    "pts2Rp = camR.project(pts3)\n",
    "plt.imshow(imgR)\n",
    "plt.plot(pts2Rp[0,:],pts2Rp[1,:],'bo')\n",
    "plt.plot(pts2R[0,:],pts2R[1,:],'rx')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below provides a visualization of the estimate camera positions relative to the checkerboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate coordinates of a line segment running from the center\n",
    "# of the camera to 3 units in front of the camera\n",
    "lookL = np.hstack((camL.t,camL.t+camL.R @ np.array([[0,0,2]]).T))\n",
    "lookR = np.hstack((camR.t,camR.t+camR.R @ np.array([[0,0,2]]).T))\n",
    "\n",
    "# visualize the left and right image overlaid\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2,2,1,projection='3d')\n",
    "ax.plot(pts3[0,:],pts3[1,:],pts3[2,:],'.')\n",
    "ax.plot(pts3r[0,:],pts3r[1,:],pts3r[2,:],'rx')\n",
    "ax.plot(camR.t[0],camR.t[1],camR.t[2],'ro')\n",
    "ax.plot(camL.t[0],camL.t[1],camL.t[2],'bo')\n",
    "ax.plot(lookL[0,:],lookL[1,:],lookL[2,:],'b')\n",
    "ax.plot(lookR[0,:],lookR[1,:],lookR[2,:],'r')\n",
    "visutils.set_axes_equal_3d(ax)\n",
    "visutils.label_axes(ax)\n",
    "plt.title('scene 3D view')\n",
    "\n",
    "ax = fig.add_subplot(2,2,2)\n",
    "ax.plot(pts3[0,:],pts3[2,:],'.')\n",
    "ax.plot(pts3r[0,:],pts3r[2,:],'rx')\n",
    "ax.plot(camR.t[0],camR.t[2],'ro')\n",
    "ax.plot(camL.t[0],camL.t[2],'bo')\n",
    "ax.plot(lookL[0,:],lookL[2,:],'b')\n",
    "ax.plot(lookR[0,:],lookR[2,:],'r')\n",
    "plt.title('XZ-view')\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('z')\n",
    "\n",
    "ax = fig.add_subplot(2,2,3)\n",
    "ax.plot(pts3[1,:],pts3[2,:],'.')\n",
    "ax.plot(pts3r[1,:],pts3r[2,:],'rx')\n",
    "ax.plot(camR.t[1],camR.t[2],'ro')\n",
    "ax.plot(camL.t[1],camL.t[2],'bo')\n",
    "ax.plot(lookL[1,:],lookL[2,:],'b')\n",
    "ax.plot(lookR[1,:],lookR[2,:],'r')\n",
    "plt.title('YZ-view')\n",
    "plt.grid()\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('z')\n",
    "\n",
    "ax = fig.add_subplot(2,2,4)\n",
    "ax.plot(pts3[0,:],pts3[1,:],'.')\n",
    "ax.plot(pts3r[0,:],pts3r[1,:],'rx')\n",
    "ax.plot(camR.t[0],camR.t[1],'ro')\n",
    "ax.plot(camL.t[0],camL.t[1],'bo')\n",
    "ax.plot(lookL[0,:],lookL[1,:],'b')\n",
    "ax.plot(lookR[0,:],lookR[1,:],'r')\n",
    "plt.title('XY-view')\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.2 Recovered Pose\n",
    "Using the provided calibration images, what are the recovered parameters for the left and right cameras?  How far apart are the camera centers in centimeters (i.e. what is the baseline) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.3 Reconstruction Accuracy\n",
    "\n",
    "Using the estimated camL and camR and the 2D point locations, triangulate to get 3D locations. What is the average error (in cm) for your recovered 3D locations of the grid corner points relative to their true coordinates?  Where might this error be coming from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.4 Focal Length\n",
    "\n",
    "The checkerboard photos were taken with an iPhone Xs. Teardowns of this device reveal that the sensor 5.6mm x 4.2mm in size. Based on this and your recovered value for f, what was the focal length in millimeters? Explain how you computed this. Is the result you get a reasonable match to the published focal length of of 4.25mm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
